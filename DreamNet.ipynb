{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u77XGv63dPy8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import imageio\n",
        "from IPython.display import Image as Img\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "nn = tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndTCIfshtigu"
      },
      "outputs": [],
      "source": [
        "IMG_PATH_1 = \"/content/dream_input.jpg\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXY9juA4v3KG"
      },
      "source": [
        "# DeepDream: [Inceptionism-Going Deeper into Neural Networks](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCwp5jYCEgFu"
      },
      "source": [
        "### Blog\n",
        "* Instead of exactly prescribing which feature we want the network to amplify, we can also let the network makethat decision. In this case we simply feed the network an arbitrary image or photo and let the network analyze thepicture. We then pick a layer and ask the network to enhance whatever it detected. Each layer of the networkdeals with features at a different level of abstraction, so the complexity of features we generate depends onwhich layer we choose to enhance.\n",
        "---\n",
        "* Lower layers tend to produce strokes or simple ornament-likepatterns, because those layers are sensitive to basic features such as edges and their orientations.\n",
        "---\n",
        "* If we choose higher-level layers, which identify more sophisticated features in images, complex features or evenwhole objects tend to emerge. Again, we just start with an existing image and give it to our neural net. We ask thenetwork: “Whatever you see there, I want more of it!”\n",
        "---\n",
        "* Example: if a cloud looks a little bit like a bird, the network will make it look more like a bird. This in turn will make the network recognize the bird\n",
        "even more strongly on the next pass and so forth, until a highly detailed bird appears, seemingly out of nowhere.\n",
        "---\n",
        "* This technique gives us a qualitative sense of the level of abstraction that a particular layer has achieved in itsunderstanding of images.\n",
        "---\n",
        "* If we apply the algorithm iteratively on its own outputs and apply some zooming after each iteration, we get an endless stream of new impressions, exploring the set of things the network knows about. We can even start this process from a random-noise image, so that the result becomes purely the result of the neural network, as seen in the following [***images***](https://photos.google.com/share/AF1QipPX0SCl7OzWilt9LnuQliattX4OUCj_8EP65_cTVnBmS1jnYgsGQAieQUc1VQWdgQ?key=aVBxWjhwSzg2RjJWLWRuVFBBZEN1d205bUdEMnhB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FldFel7hG-I7"
      },
      "source": [
        "### Details of DeepDream\n",
        "* The idea in DeepDream is to choose a layer (or layers) and maximize the \"loss\" in a way that the image increasingly \"excites\" the layers.\n",
        "---\n",
        "*  For DeepDream, the layers of interest are those where the convolutions are concatenated. There are 11 of these layers in `InceptionV3`, named `'mixed0'` though `'mixed10'`.\n",
        "---\n",
        "* Using different layers will result in different dream-like images. Deeper layers respond to higher-level features (such as eyes and faces), while earlier layers respond to simpler features (such as edges, shapes, and textures).\n",
        "---\n",
        "* Deeper layers (those with a higher index) will take longer to train on since the gradient computation is deeper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxWkiOIfGUxK",
        "outputId": "da39d4a4-aac0-4f19-8e2e-1a2cda3f7b9a"
      },
      "outputs": [],
      "source": [
        "base_model = nn.applications.InceptionV3(include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJYYvYOYj5CQ"
      },
      "outputs": [],
      "source": [
        "def path_to_image(img_path):\n",
        "  return Image.open(img_path)\n",
        "\n",
        "def deprocess(img):\n",
        "  img = 255*(img + 1.0)/2.0\n",
        "  return tf.cast(img, tf.uint8)\n",
        "\n",
        "def show(img):\n",
        "  display.display(Image.fromarray(np.array(img)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "WtsEM_FwGiqt",
        "outputId": "711ad586-1d2a-4e69-ffe3-26cf9864c965"
      },
      "outputs": [],
      "source": [
        "show(np.array(path_to_image(IMG_PATH_1))) # (360, 540, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw82VZYxyT2C"
      },
      "source": [
        "### Loss Function for Dreaming!\n",
        "\n",
        "* The loss is the sum of the activations in the chosen layers. The loss is normalized at each layer so the contribution from larger layers does not outweigh smaller layers.\n",
        "---\n",
        "* We will maximize this loss via gradient ascent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Agmy6WXlvYjK"
      },
      "outputs": [],
      "source": [
        "class DreamLoss(nn.losses.Loss):\n",
        "  \"\"\"Loss for our DeepDream Model\"\"\"\n",
        "  def call(self, image, model):\n",
        "    image_batch = image[tf.newaxis]\n",
        "    layer_activations = model(image_batch)\n",
        "    layer_activations = [layer_activations] if not isinstance(layer_activations, list) else layer_activations\n",
        "\n",
        "    # taking mean of layer activation to get a single value\n",
        "    losses = [tf.reduce_mean(activation) for activation in layer_activations] # len(losses) = number of layers selected\n",
        "    # losses calculated from all output activations are added\n",
        "    return tf.reduce_sum(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-IcbxRi11DL"
      },
      "source": [
        "# Gradient Ascent\n",
        "\n",
        "* Now we calculate the gradients with respect to the image, and add them to the original image\n",
        "---\n",
        "* Adding the gradients to the image enhances the patterns seen by the network. At each step, you will have created an image that increasingly excites the activations of certain layers in the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLGDWKaI2z_q"
      },
      "outputs": [],
      "source": [
        "class DeepDream(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function(\n",
        "      input_signature=(\n",
        "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
        "  )\n",
        "  def __call__(self, image, steps, increment):\n",
        "    loss_fn = DreamLoss()\n",
        "    for _ in tf.range(steps):\n",
        "      with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        loss = loss_fn(image, self.model)\n",
        "      gradient = tape.gradient(loss, image)\n",
        "      gradient /= (tf.math.reduce_std(gradient) + 1e-6)\n",
        "\n",
        "      image += gradient*increment # loss is maximized to exite the activations in layer output\n",
        "      image = tf.clip_by_value(image, -1, 1)\n",
        "\n",
        "    return loss, image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1gffBzp-_of"
      },
      "outputs": [],
      "source": [
        "def train(image, model, steps=150, increment=0.01):\n",
        "    image = tf.convert_to_tensor(nn.applications.inception_v3.preprocess_input(image))\n",
        "    increment = tf.convert_to_tensor(increment)\n",
        "    steps_remaining = steps\n",
        "    step = 0\n",
        "    while steps_remaining:\n",
        "        if steps_remaining>100:\n",
        "            run_steps = tf.convert_to_tensor(100)\n",
        "        else:\n",
        "            run_steps = tf.convert_to_tensor(steps_remaining)\n",
        "        steps_remaining -= run_steps\n",
        "        step += run_steps\n",
        "\n",
        "        loss, image = DeepDream(model=model)(image, run_steps, tf.constant(increment))\n",
        "\n",
        "        display.clear_output(wait=True)\n",
        "        show(deprocess(image))\n",
        "        print (f\"Step {step}, loss {loss}\")\n",
        "\n",
        "    final_image = deprocess(image)\n",
        "    display.clear_output(wait=False)\n",
        "    show(final_image)\n",
        "    return final_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb7WOmD9aF5K",
        "outputId": "6e4dcbfa-f066-49e8-aa64-3f3070b14f46"
      },
      "outputs": [],
      "source": [
        "LAYERS = [layer.name for layer in base_model.layers]\n",
        "print(\"Number of layers:\", len(LAYERS))\n",
        "layer_out = [base_model.get_layer(name).output for name in LAYERS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dreamed_image(image_path, layer_out):\n",
        "    image = np.array(path_to_image(image_path))\n",
        "    model = nn.Model(inputs=base_model.input, outputs=layer_out)\n",
        "    out_img = train(image, model, steps=200, increment=0.01)\n",
        "    return out_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "lmnLDeASTpuz",
        "outputId": "938bf533-0779-4872-a4b8-4a854b7a4be3"
      },
      "outputs": [],
      "source": [
        "def make_gif(path_to_save):\n",
        "    img_list = []\n",
        "    for i in range(len(LAYERS)):\n",
        "        out_img = dreamed_image(IMG_PATH_1, layer_out=layer_out[i])\n",
        "        img_list.append(out_img)\n",
        "    imageio.mimsave(path_to_save, tf.convert_to_tensor(img_list).numpy(), format='GIF', duration=2)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3a4XdQ8TpkW"
      },
      "outputs": [],
      "source": [
        "path = \"inception_200_001.gif\"\n",
        "make_gif(path)\n",
        "Img(filename=path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5Od45fETpfb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
